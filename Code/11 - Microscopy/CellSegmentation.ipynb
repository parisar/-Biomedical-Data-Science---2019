{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CellSegmentation.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"5Y8ZyWn21L01","colab_type":"text"},"source":["This code is adapted based on code examples in Ramsundar, Bharath; Eastman, Peter; Walters, Patrick; Pande, Vijay. Deep Learning for the Life Sciences, Chapter 7."]},{"cell_type":"markdown","metadata":{"id":"Qnn5P5axItKh","colab_type":"text"},"source":["# Installing DeepChem"]},{"cell_type":"code","metadata":{"id":"b_CZcX8FsuIF","colab_type":"code","colab":{}},"source":["# Installing RDKit\n","!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","!chmod +x Miniconda3-latest-Linux-x86_64.sh\n","!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n","!time conda install -q -y -c conda-forge rdkit"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bp0CouRSthbz","colab_type":"code","colab":{}},"source":["# append rdkit path to current python system path.\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import sys\n","import os\n","sys.path.append('/usr/local/lib/python3.7/site-packages/')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R16Y3UW2rCED","colab_type":"code","colab":{}},"source":["# Install DeepChem \n","!pip install deepchem"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AI_-BZZEvcRJ","colab_type":"code","colab":{}},"source":["import deepchem as dc\n","import deepchem.models.tensorgraph.layers as layers\n","import numpy as np\n","import os\n","import re"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LryaglrSIUpq","colab_type":"text"},"source":["# Dataset\n","To run this example, you will need to download the Broad BBBC005 dataset from https://data.broadinstitute.org/bbbc/BBBC005/. No login or registration is needed to download this dataset, so the raw images can simply be fetched with\n","\n","! wget https://data.broadinstitute.org/bbbc/BBBC005/BBBC005_v1_images.zip unzip BBBC005_v1_images.zip\n","\n","The ground-truth segmentation masks can be fetched as follows\n","\n","! wget https://data.broadinstitute.org/bbbc/BBBC005/BBBC005_v1_ground_truth.zip unzip BBBC005_v1_ground_truth.zip"]},{"cell_type":"code","metadata":{"id":"B9Z_9zM7wGcK","colab_type":"code","colab":{}},"source":["# The ground-truth segmentation masks can be fetched as follows\n","\n","! wget https://data.broadinstitute.org/bbbc/BBBC005/BBBC005_v1_ground_truth.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"X_zH8fapsjRL","colab":{}},"source":["! unzip BBBC005_v1_ground_truth.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IupuZhFMg8Jm","colab_type":"code","colab":{}},"source":["# check the files on colab drive\n","! ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VaNrITXfxS2U","colab_type":"code","colab":{}},"source":["# Load the datasets.\n","image_dir = 'BBBC005_v1_images'\n","label_dir = 'BBBC005_v1_ground_truth'\n","rows = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P')\n","blurs = (1, 4, 7, 10, 14, 17, 20, 23, 26, 29, 32, 35, 39, 42, 45, 48)\n","files = []\n","labels = []\n","for f in os.listdir(label_dir):\n","  if f.endswith('.TIF'):\n","    for row, blur in zip(rows, blurs):\n","      fname = f.replace('_F1', '_F%d'%blur).replace('_A', '_%s'%row)\n","      files.append(os.path.join(image_dir, fname))\n","      labels.append(os.path.join(label_dir, f))\n","\n","loader = dc.data.ImageLoader()\n","dataset = loader.featurize(files, labels)\n","splitter = dc.splits.RandomSplitter()\n","train_dataset, valid_dataset, test_dataset = splitter.train_valid_test_split(dataset, seed=123)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H3OVBs0k1VPG","colab_type":"code","colab":{}},"source":["# inspect the sets\n","print('Size of the training set: ', train_dataset.get_shape())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P6CrvdjjI2Si","colab_type":"text"},"source":["# Building the Model"]},{"cell_type":"markdown","metadata":{"id":"Fsfo3DqU2eBK","colab_type":"text"},"source":["It will take some time to train a model on this dataset. It might be best if you download the pretrained models instead. "]},{"cell_type":"code","metadata":{"id":"V_mkf_da3c4-","colab_type":"code","colab":{}},"source":["RETRAIN = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"udwKcjZJ5bsX","colab_type":"code","colab":{}},"source":["# Create the model.\n","learning_rate = dc.models.tensorgraph.optimizers.ExponentialDecay(0.01, 0.9, 250)\n","model = dc.models.TensorGraph(learning_rate=learning_rate, model_dir='models/segmentation')\n","features = layers.Feature(shape=(None, 520, 696, 1)) / 255.0\n","labels = layers.Label(shape=(None, 520, 696, 1)) / 255.0\n","# Downsample three times.\n","conv1 = layers.Conv2D(16, kernel_size=5, stride=2, in_layers=features)\n","conv2 = layers.Conv2D(32, kernel_size=5, stride=2, in_layers=conv1)\n","conv3 = layers.Conv2D(64, kernel_size=5, stride=2, in_layers=conv2)\n","# Do a 1x1 convolution.\n","conv4 = layers.Conv2D(64, kernel_size=1, stride=1, in_layers=conv3)\n","# Upsample three times.\n","concat1 = layers.Concat(in_layers=[conv3, conv4], axis=3)\n","deconv1 = layers.Conv2DTranspose(32, kernel_size=5, stride=2, in_layers=concat1)\n","concat2 = layers.Concat(in_layers=[conv2, deconv1], axis=3)\n","deconv2 = layers.Conv2DTranspose(16, kernel_size=5, stride=2, in_layers=concat2)\n","concat3 = layers.Concat(in_layers=[conv1, deconv2], axis=3)\n","deconv3 = layers.Conv2DTranspose(1, kernel_size=5, stride=2, in_layers=concat3)\n","# Compute the final output.\n","concat4 = layers.Concat(in_layers=[features, deconv3], axis=3)\n","logits = layers.Conv2D(1, kernel_size=5, stride=1, activation_fn=None, in_layers=concat4)\n","output = layers.Sigmoid(logits)\n","model.add_output(output)\n","loss = layers.ReduceSum(layers.SigmoidCrossEntropy(in_layers=(labels, logits)))\n","model.set_loss(loss)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CmvIxDsSrvZi","colab_type":"code","colab":{}},"source":["if not os.path.exists('./models'):\n","  os.mkdir('models')\n","if not os.path.exists('./models/segmentation'):\n","  os.mkdir('models/segmentation')\n","\n","if not RETRAIN:\n","  model.restore()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yZTNPWIVI9aa","colab_type":"text"},"source":["# Displaying the Results"]},{"cell_type":"code","metadata":{"id":"buL6G5hxESo0","colab_type":"code","colab":{}},"source":["# Train it and evaluate performance on the test set.\n","if RETRAIN:\n","  print(\"About to fit model for 50 epochs\")\n","  model.fit(train_dataset, nb_epoch=50, checkpoint_interval=100)\n","scores = []\n","for x, y, w, id in test_dataset.itersamples():\n","  y_pred = model.predict_on_batch([x]).squeeze()\n","  scores.append(np.mean((y>0) == (y_pred>0.5)))\n","print(np.mean(scores))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VeHL9fZti_ZP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}