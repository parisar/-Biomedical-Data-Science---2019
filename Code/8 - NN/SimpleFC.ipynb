{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3    4     5      6   7  8\n",
       "0  6  148  72  35    0  33.6  0.627  50  1\n",
       "1  1   85  66  29    0  26.6  0.351  31  0\n",
       "2  8  183  64   0    0  23.3  0.672  32  1\n",
       "3  1   89  66  23   94  28.1  0.167  21  0\n",
       "4  0  137  40  35  168  43.1  2.288  33  1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pima indians dataset from its web address\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data', header = None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1           2           3           4           5  \\\n",
       "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
       "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
       "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
       "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
       "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "                6           7           8  \n",
       "count  768.000000  768.000000  768.000000  \n",
       "mean     0.471876   33.240885    0.348958  \n",
       "std      0.331329   11.760232    0.476951  \n",
       "min      0.078000   21.000000    0.000000  \n",
       "25%      0.243750   24.000000    0.000000  \n",
       "50%      0.372500   29.000000    0.000000  \n",
       "75%      0.626250   41.000000    1.000000  \n",
       "max      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert to numpy array\n",
    "data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into features (X) and labels (Y)\n",
    "X = data[:,0:8]\n",
    "Y = data[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, Y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a fully connected model, as a sequential class\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fully connected layers are defined using Dense class. We define three layers: 2 hidden layers + output layer.\n",
    "model.add(Dense(output_dim=15, input_dim=8, init='uniform', activation='relu'))\n",
    "model.add(Dense(output_dim=8, init='uniform', activation='relu'))\n",
    "model.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 537 samples, validate on 231 samples\n",
      "Epoch 1/150\n",
      "537/537 [==============================] - 0s - loss: 0.4078 - acc: 0.8212 - val_loss: 0.4695 - val_acc: 0.8009\n",
      "Epoch 2/150\n",
      "537/537 [==============================] - 0s - loss: 0.3974 - acc: 0.8045 - val_loss: 0.4813 - val_acc: 0.7749\n",
      "Epoch 3/150\n",
      "537/537 [==============================] - 0s - loss: 0.4049 - acc: 0.8082 - val_loss: 0.4898 - val_acc: 0.7706\n",
      "Epoch 4/150\n",
      "537/537 [==============================] - 0s - loss: 0.4069 - acc: 0.8119 - val_loss: 0.4756 - val_acc: 0.7835\n",
      "Epoch 5/150\n",
      "537/537 [==============================] - 0s - loss: 0.3913 - acc: 0.8194 - val_loss: 0.4681 - val_acc: 0.8052\n",
      "Epoch 6/150\n",
      "537/537 [==============================] - 0s - loss: 0.4031 - acc: 0.8231 - val_loss: 0.4766 - val_acc: 0.7922\n",
      "Epoch 7/150\n",
      "537/537 [==============================] - 0s - loss: 0.3931 - acc: 0.8045 - val_loss: 0.4890 - val_acc: 0.8009\n",
      "Epoch 8/150\n",
      "537/537 [==============================] - 0s - loss: 0.4139 - acc: 0.8119 - val_loss: 0.4784 - val_acc: 0.8139\n",
      "Epoch 9/150\n",
      "537/537 [==============================] - 0s - loss: 0.3993 - acc: 0.8045 - val_loss: 0.4960 - val_acc: 0.7879\n",
      "Epoch 10/150\n",
      "537/537 [==============================] - 0s - loss: 0.4091 - acc: 0.7970 - val_loss: 0.4999 - val_acc: 0.7662\n",
      "Epoch 11/150\n",
      "537/537 [==============================] - 0s - loss: 0.4062 - acc: 0.8250 - val_loss: 0.4828 - val_acc: 0.7879\n",
      "Epoch 12/150\n",
      "537/537 [==============================] - 0s - loss: 0.3996 - acc: 0.8045 - val_loss: 0.4873 - val_acc: 0.7965\n",
      "Epoch 13/150\n",
      "537/537 [==============================] - 0s - loss: 0.4057 - acc: 0.8119 - val_loss: 0.4946 - val_acc: 0.7879\n",
      "Epoch 14/150\n",
      "537/537 [==============================] - 0s - loss: 0.4077 - acc: 0.8045 - val_loss: 0.5311 - val_acc: 0.7792\n",
      "Epoch 15/150\n",
      "537/537 [==============================] - 0s - loss: 0.4190 - acc: 0.8007 - val_loss: 0.4968 - val_acc: 0.7965\n",
      "Epoch 16/150\n",
      "537/537 [==============================] - 0s - loss: 0.3880 - acc: 0.8324 - val_loss: 0.4931 - val_acc: 0.7965\n",
      "Epoch 17/150\n",
      "537/537 [==============================] - 0s - loss: 0.4114 - acc: 0.7970 - val_loss: 0.4818 - val_acc: 0.7835\n",
      "Epoch 18/150\n",
      "537/537 [==============================] - 0s - loss: 0.4055 - acc: 0.8045 - val_loss: 0.4891 - val_acc: 0.7749\n",
      "Epoch 19/150\n",
      "537/537 [==============================] - 0s - loss: 0.3883 - acc: 0.8119 - val_loss: 0.4742 - val_acc: 0.7879\n",
      "Epoch 20/150\n",
      "537/537 [==============================] - 0s - loss: 0.4138 - acc: 0.8175 - val_loss: 0.5120 - val_acc: 0.7792\n",
      "Epoch 21/150\n",
      "537/537 [==============================] - 0s - loss: 0.4205 - acc: 0.7952 - val_loss: 0.4969 - val_acc: 0.7879\n",
      "Epoch 22/150\n",
      "537/537 [==============================] - 0s - loss: 0.4146 - acc: 0.8007 - val_loss: 0.4806 - val_acc: 0.8009\n",
      "Epoch 23/150\n",
      "537/537 [==============================] - 0s - loss: 0.4053 - acc: 0.8007 - val_loss: 0.4891 - val_acc: 0.8139\n",
      "Epoch 24/150\n",
      "537/537 [==============================] - 0s - loss: 0.3843 - acc: 0.8175 - val_loss: 0.4698 - val_acc: 0.7835\n",
      "Epoch 25/150\n",
      "537/537 [==============================] - 0s - loss: 0.3939 - acc: 0.8045 - val_loss: 0.4878 - val_acc: 0.7792\n",
      "Epoch 26/150\n",
      "537/537 [==============================] - 0s - loss: 0.3908 - acc: 0.8361 - val_loss: 0.4809 - val_acc: 0.7835\n",
      "Epoch 27/150\n",
      "537/537 [==============================] - 0s - loss: 0.3967 - acc: 0.8175 - val_loss: 0.5506 - val_acc: 0.7706\n",
      "Epoch 28/150\n",
      "537/537 [==============================] - 0s - loss: 0.3974 - acc: 0.8045 - val_loss: 0.5079 - val_acc: 0.7835\n",
      "Epoch 29/150\n",
      "537/537 [==============================] - 0s - loss: 0.3920 - acc: 0.8175 - val_loss: 0.4973 - val_acc: 0.7965\n",
      "Epoch 30/150\n",
      "537/537 [==============================] - 0s - loss: 0.4105 - acc: 0.8156 - val_loss: 0.5541 - val_acc: 0.7706\n",
      "Epoch 31/150\n",
      "537/537 [==============================] - 0s - loss: 0.3971 - acc: 0.8101 - val_loss: 0.4860 - val_acc: 0.7749\n",
      "Epoch 32/150\n",
      "537/537 [==============================] - 0s - loss: 0.3907 - acc: 0.8212 - val_loss: 0.4809 - val_acc: 0.8052\n",
      "Epoch 33/150\n",
      "537/537 [==============================] - 0s - loss: 0.4114 - acc: 0.8026 - val_loss: 0.4948 - val_acc: 0.7835\n",
      "Epoch 34/150\n",
      "537/537 [==============================] - 0s - loss: 0.3955 - acc: 0.8138 - val_loss: 0.5161 - val_acc: 0.7922\n",
      "Epoch 35/150\n",
      "537/537 [==============================] - 0s - loss: 0.4121 - acc: 0.8119 - val_loss: 0.4807 - val_acc: 0.7792\n",
      "Epoch 36/150\n",
      "537/537 [==============================] - 0s - loss: 0.3982 - acc: 0.8119 - val_loss: 0.4891 - val_acc: 0.8139\n",
      "Epoch 37/150\n",
      "537/537 [==============================] - 0s - loss: 0.3916 - acc: 0.8082 - val_loss: 0.4811 - val_acc: 0.7965\n",
      "Epoch 38/150\n",
      "537/537 [==============================] - 0s - loss: 0.3942 - acc: 0.8175 - val_loss: 0.5206 - val_acc: 0.7749\n",
      "Epoch 39/150\n",
      "537/537 [==============================] - 0s - loss: 0.3981 - acc: 0.8082 - val_loss: 0.5088 - val_acc: 0.7749\n",
      "Epoch 40/150\n",
      "537/537 [==============================] - 0s - loss: 0.3964 - acc: 0.8138 - val_loss: 0.4895 - val_acc: 0.7879\n",
      "Epoch 41/150\n",
      "537/537 [==============================] - 0s - loss: 0.4085 - acc: 0.8063 - val_loss: 0.4899 - val_acc: 0.8139\n",
      "Epoch 42/150\n",
      "537/537 [==============================] - 0s - loss: 0.3848 - acc: 0.8156 - val_loss: 0.4877 - val_acc: 0.8052\n",
      "Epoch 43/150\n",
      "537/537 [==============================] - 0s - loss: 0.3962 - acc: 0.8175 - val_loss: 0.5059 - val_acc: 0.7922\n",
      "Epoch 44/150\n",
      "537/537 [==============================] - 0s - loss: 0.4003 - acc: 0.8063 - val_loss: 0.4923 - val_acc: 0.8052\n",
      "Epoch 45/150\n",
      "537/537 [==============================] - 0s - loss: 0.3900 - acc: 0.8268 - val_loss: 0.4874 - val_acc: 0.8139\n",
      "Epoch 46/150\n",
      "537/537 [==============================] - 0s - loss: 0.3914 - acc: 0.8101 - val_loss: 0.4884 - val_acc: 0.7965\n",
      "Epoch 47/150\n",
      "537/537 [==============================] - 0s - loss: 0.4030 - acc: 0.8175 - val_loss: 0.4874 - val_acc: 0.7749\n",
      "Epoch 48/150\n",
      "537/537 [==============================] - 0s - loss: 0.3903 - acc: 0.8175 - val_loss: 0.4835 - val_acc: 0.7965\n",
      "Epoch 49/150\n",
      "537/537 [==============================] - 0s - loss: 0.3872 - acc: 0.8287 - val_loss: 0.4864 - val_acc: 0.8052\n",
      "Epoch 50/150\n",
      "537/537 [==============================] - 0s - loss: 0.4062 - acc: 0.8082 - val_loss: 0.5097 - val_acc: 0.7792\n",
      "Epoch 51/150\n",
      "537/537 [==============================] - 0s - loss: 0.3954 - acc: 0.8082 - val_loss: 0.4937 - val_acc: 0.7792\n",
      "Epoch 52/150\n",
      "537/537 [==============================] - 0s - loss: 0.3915 - acc: 0.8119 - val_loss: 0.4870 - val_acc: 0.7835\n",
      "Epoch 53/150\n",
      "537/537 [==============================] - 0s - loss: 0.3962 - acc: 0.8268 - val_loss: 0.4847 - val_acc: 0.7706\n",
      "Epoch 54/150\n",
      "537/537 [==============================] - 0s - loss: 0.3981 - acc: 0.8119 - val_loss: 0.4922 - val_acc: 0.8009\n",
      "Epoch 55/150\n",
      "537/537 [==============================] - 0s - loss: 0.4064 - acc: 0.8194 - val_loss: 0.4943 - val_acc: 0.7835\n",
      "Epoch 56/150\n",
      "537/537 [==============================] - 0s - loss: 0.4241 - acc: 0.8045 - val_loss: 0.4834 - val_acc: 0.7835\n",
      "Epoch 57/150\n",
      "537/537 [==============================] - 0s - loss: 0.4024 - acc: 0.8026 - val_loss: 0.4843 - val_acc: 0.7922\n",
      "Epoch 58/150\n",
      "537/537 [==============================] - 0s - loss: 0.3997 - acc: 0.8268 - val_loss: 0.4936 - val_acc: 0.8095\n",
      "Epoch 59/150\n",
      "537/537 [==============================] - 0s - loss: 0.4196 - acc: 0.7952 - val_loss: 0.4952 - val_acc: 0.7792\n",
      "Epoch 60/150\n",
      "537/537 [==============================] - 0s - loss: 0.4026 - acc: 0.8194 - val_loss: 0.5042 - val_acc: 0.7879\n",
      "Epoch 61/150\n",
      "537/537 [==============================] - 0s - loss: 0.3826 - acc: 0.8175 - val_loss: 0.4876 - val_acc: 0.7922\n",
      "Epoch 62/150\n",
      "537/537 [==============================] - 0s - loss: 0.3982 - acc: 0.8194 - val_loss: 0.4994 - val_acc: 0.8139\n",
      "Epoch 63/150\n",
      "537/537 [==============================] - 0s - loss: 0.4042 - acc: 0.8026 - val_loss: 0.5293 - val_acc: 0.7706\n",
      "Epoch 64/150\n",
      "537/537 [==============================] - 0s - loss: 0.3994 - acc: 0.7989 - val_loss: 0.4719 - val_acc: 0.7749\n",
      "Epoch 65/150\n",
      "537/537 [==============================] - 0s - loss: 0.3925 - acc: 0.8175 - val_loss: 0.4912 - val_acc: 0.7835\n",
      "Epoch 66/150\n",
      "537/537 [==============================] - 0s - loss: 0.3853 - acc: 0.8194 - val_loss: 0.4916 - val_acc: 0.8009\n",
      "Epoch 67/150\n",
      "537/537 [==============================] - 0s - loss: 0.4137 - acc: 0.8156 - val_loss: 0.4957 - val_acc: 0.7879\n",
      "Epoch 68/150\n",
      "537/537 [==============================] - 0s - loss: 0.3901 - acc: 0.8156 - val_loss: 0.4938 - val_acc: 0.8139\n",
      "Epoch 69/150\n",
      "537/537 [==============================] - 0s - loss: 0.4036 - acc: 0.8119 - val_loss: 0.5244 - val_acc: 0.7749\n",
      "Epoch 70/150\n",
      "537/537 [==============================] - 0s - loss: 0.3946 - acc: 0.8045 - val_loss: 0.4919 - val_acc: 0.7835\n",
      "Epoch 71/150\n",
      "537/537 [==============================] - 0s - loss: 0.4004 - acc: 0.8101 - val_loss: 0.5184 - val_acc: 0.7749\n",
      "Epoch 72/150\n",
      "537/537 [==============================] - 0s - loss: 0.4015 - acc: 0.8175 - val_loss: 0.4853 - val_acc: 0.7879\n",
      "Epoch 73/150\n",
      "537/537 [==============================] - 0s - loss: 0.3922 - acc: 0.8156 - val_loss: 0.4874 - val_acc: 0.7792\n",
      "Epoch 74/150\n",
      "537/537 [==============================] - 0s - loss: 0.3845 - acc: 0.8231 - val_loss: 0.4864 - val_acc: 0.7835\n",
      "Epoch 75/150\n",
      "537/537 [==============================] - 0s - loss: 0.3940 - acc: 0.8156 - val_loss: 0.5095 - val_acc: 0.8095\n",
      "Epoch 76/150\n",
      "537/537 [==============================] - 0s - loss: 0.4019 - acc: 0.8175 - val_loss: 0.4841 - val_acc: 0.8009\n",
      "Epoch 77/150\n",
      "537/537 [==============================] - 0s - loss: 0.4034 - acc: 0.8045 - val_loss: 0.4808 - val_acc: 0.8095\n",
      "Epoch 78/150\n",
      "537/537 [==============================] - 0s - loss: 0.4061 - acc: 0.8063 - val_loss: 0.5118 - val_acc: 0.7706\n",
      "Epoch 79/150\n",
      "537/537 [==============================] - 0s - loss: 0.3896 - acc: 0.8194 - val_loss: 0.4875 - val_acc: 0.7835\n",
      "Epoch 80/150\n",
      "537/537 [==============================] - 0s - loss: 0.3856 - acc: 0.8156 - val_loss: 0.4908 - val_acc: 0.8139\n",
      "Epoch 81/150\n",
      "537/537 [==============================] - 0s - loss: 0.4015 - acc: 0.8156 - val_loss: 0.5238 - val_acc: 0.7576\n",
      "Epoch 82/150\n",
      "537/537 [==============================] - 0s - loss: 0.4040 - acc: 0.8082 - val_loss: 0.4993 - val_acc: 0.7835\n",
      "Epoch 83/150\n",
      "537/537 [==============================] - 0s - loss: 0.3916 - acc: 0.8250 - val_loss: 0.5168 - val_acc: 0.7835\n",
      "Epoch 84/150\n",
      "537/537 [==============================] - 0s - loss: 0.3951 - acc: 0.8212 - val_loss: 0.4879 - val_acc: 0.8052\n",
      "Epoch 85/150\n",
      "537/537 [==============================] - 0s - loss: 0.4043 - acc: 0.8138 - val_loss: 0.5055 - val_acc: 0.7965\n",
      "Epoch 86/150\n",
      "537/537 [==============================] - 0s - loss: 0.4001 - acc: 0.8138 - val_loss: 0.5021 - val_acc: 0.7792\n",
      "Epoch 87/150\n",
      "537/537 [==============================] - 0s - loss: 0.3843 - acc: 0.8101 - val_loss: 0.5038 - val_acc: 0.7922\n",
      "Epoch 88/150\n",
      "537/537 [==============================] - 0s - loss: 0.3858 - acc: 0.8250 - val_loss: 0.4793 - val_acc: 0.7792\n",
      "Epoch 89/150\n",
      "537/537 [==============================] - 0s - loss: 0.4012 - acc: 0.8156 - val_loss: 0.5061 - val_acc: 0.7879\n",
      "Epoch 90/150\n",
      "537/537 [==============================] - 0s - loss: 0.4000 - acc: 0.8156 - val_loss: 0.5114 - val_acc: 0.7965\n",
      "Epoch 91/150\n",
      "537/537 [==============================] - 0s - loss: 0.3955 - acc: 0.8324 - val_loss: 0.4916 - val_acc: 0.8139\n",
      "Epoch 92/150\n",
      "537/537 [==============================] - 0s - loss: 0.3849 - acc: 0.8082 - val_loss: 0.4940 - val_acc: 0.7835\n",
      "Epoch 93/150\n",
      "537/537 [==============================] - 0s - loss: 0.3843 - acc: 0.8138 - val_loss: 0.5146 - val_acc: 0.8052\n",
      "Epoch 94/150\n",
      "537/537 [==============================] - 0s - loss: 0.3970 - acc: 0.8101 - val_loss: 0.4927 - val_acc: 0.7792\n",
      "Epoch 95/150\n",
      "537/537 [==============================] - 0s - loss: 0.4209 - acc: 0.7970 - val_loss: 0.4950 - val_acc: 0.8009\n",
      "Epoch 96/150\n",
      "537/537 [==============================] - 0s - loss: 0.3860 - acc: 0.8175 - val_loss: 0.5091 - val_acc: 0.7965\n",
      "Epoch 97/150\n",
      "537/537 [==============================] - 0s - loss: 0.3917 - acc: 0.8175 - val_loss: 0.5077 - val_acc: 0.7835\n",
      "Epoch 98/150\n",
      "537/537 [==============================] - 0s - loss: 0.3895 - acc: 0.8194 - val_loss: 0.5413 - val_acc: 0.7749\n",
      "Epoch 99/150\n",
      "537/537 [==============================] - 0s - loss: 0.3951 - acc: 0.8194 - val_loss: 0.5904 - val_acc: 0.7532\n",
      "Epoch 100/150\n",
      "537/537 [==============================] - 0s - loss: 0.4029 - acc: 0.8268 - val_loss: 0.5044 - val_acc: 0.7662\n",
      "Epoch 101/150\n",
      "537/537 [==============================] - 0s - loss: 0.3932 - acc: 0.8082 - val_loss: 0.5175 - val_acc: 0.7792\n",
      "Epoch 102/150\n",
      "537/537 [==============================] - 0s - loss: 0.3861 - acc: 0.8212 - val_loss: 0.5124 - val_acc: 0.7879\n",
      "Epoch 103/150\n",
      "537/537 [==============================] - 0s - loss: 0.3955 - acc: 0.8175 - val_loss: 0.4831 - val_acc: 0.7662\n",
      "Epoch 104/150\n",
      "537/537 [==============================] - 0s - loss: 0.3896 - acc: 0.8156 - val_loss: 0.5106 - val_acc: 0.8095\n",
      "Epoch 105/150\n",
      "537/537 [==============================] - 0s - loss: 0.3928 - acc: 0.8268 - val_loss: 0.5038 - val_acc: 0.7749\n",
      "Epoch 106/150\n",
      "537/537 [==============================] - 0s - loss: 0.3892 - acc: 0.8212 - val_loss: 0.5464 - val_acc: 0.7619\n",
      "Epoch 107/150\n",
      "537/537 [==============================] - 0s - loss: 0.3913 - acc: 0.8101 - val_loss: 0.4934 - val_acc: 0.7792\n",
      "Epoch 108/150\n",
      "537/537 [==============================] - 0s - loss: 0.3879 - acc: 0.8250 - val_loss: 0.5441 - val_acc: 0.7879\n",
      "Epoch 109/150\n",
      "537/537 [==============================] - 0s - loss: 0.3872 - acc: 0.8250 - val_loss: 0.4884 - val_acc: 0.7792\n",
      "Epoch 110/150\n",
      "537/537 [==============================] - 0s - loss: 0.3874 - acc: 0.8212 - val_loss: 0.5172 - val_acc: 0.7706\n",
      "Epoch 111/150\n",
      "537/537 [==============================] - 0s - loss: 0.3965 - acc: 0.8212 - val_loss: 0.5029 - val_acc: 0.7706\n",
      "Epoch 112/150\n",
      "537/537 [==============================] - 0s - loss: 0.3944 - acc: 0.8138 - val_loss: 0.5088 - val_acc: 0.7965\n",
      "Epoch 113/150\n",
      "537/537 [==============================] - 0s - loss: 0.3895 - acc: 0.8138 - val_loss: 0.4844 - val_acc: 0.7879\n",
      "Epoch 114/150\n",
      "537/537 [==============================] - 0s - loss: 0.4188 - acc: 0.7970 - val_loss: 0.5079 - val_acc: 0.7835\n",
      "Epoch 115/150\n",
      "537/537 [==============================] - 0s - loss: 0.3921 - acc: 0.8268 - val_loss: 0.4917 - val_acc: 0.8052\n",
      "Epoch 116/150\n",
      "537/537 [==============================] - 0s - loss: 0.4053 - acc: 0.7933 - val_loss: 0.5250 - val_acc: 0.7706\n",
      "Epoch 117/150\n",
      "537/537 [==============================] - 0s - loss: 0.3841 - acc: 0.8417 - val_loss: 0.4943 - val_acc: 0.7879\n",
      "Epoch 118/150\n",
      "537/537 [==============================] - 0s - loss: 0.4012 - acc: 0.8268 - val_loss: 0.4894 - val_acc: 0.7922\n",
      "Epoch 119/150\n",
      "537/537 [==============================] - 0s - loss: 0.3989 - acc: 0.8045 - val_loss: 0.4891 - val_acc: 0.7879\n",
      "Epoch 120/150\n",
      "537/537 [==============================] - 0s - loss: 0.3911 - acc: 0.8082 - val_loss: 0.4807 - val_acc: 0.8009\n",
      "Epoch 121/150\n",
      "537/537 [==============================] - 0s - loss: 0.3951 - acc: 0.8212 - val_loss: 0.4814 - val_acc: 0.7792\n",
      "Epoch 122/150\n",
      "537/537 [==============================] - 0s - loss: 0.3889 - acc: 0.8082 - val_loss: 0.4901 - val_acc: 0.8095\n",
      "Epoch 123/150\n",
      "537/537 [==============================] - 0s - loss: 0.3916 - acc: 0.8082 - val_loss: 0.4862 - val_acc: 0.7792\n",
      "Epoch 124/150\n",
      "537/537 [==============================] - 0s - loss: 0.3762 - acc: 0.8231 - val_loss: 0.5075 - val_acc: 0.8009\n",
      "Epoch 125/150\n",
      "537/537 [==============================] - 0s - loss: 0.3966 - acc: 0.7914 - val_loss: 0.5089 - val_acc: 0.7835\n",
      "Epoch 126/150\n",
      "537/537 [==============================] - 0s - loss: 0.4043 - acc: 0.8101 - val_loss: 0.5112 - val_acc: 0.7879\n",
      "Epoch 127/150\n",
      "537/537 [==============================] - 0s - loss: 0.3829 - acc: 0.8287 - val_loss: 0.5446 - val_acc: 0.7835\n",
      "Epoch 128/150\n",
      "537/537 [==============================] - 0s - loss: 0.3914 - acc: 0.8194 - val_loss: 0.5041 - val_acc: 0.7922\n",
      "Epoch 129/150\n",
      "537/537 [==============================] - 0s - loss: 0.3810 - acc: 0.8287 - val_loss: 0.5143 - val_acc: 0.8009\n",
      "Epoch 130/150\n",
      "537/537 [==============================] - 0s - loss: 0.3841 - acc: 0.8343 - val_loss: 0.5260 - val_acc: 0.7706\n",
      "Epoch 131/150\n",
      "537/537 [==============================] - 0s - loss: 0.3908 - acc: 0.8045 - val_loss: 0.5058 - val_acc: 0.8009\n",
      "Epoch 132/150\n",
      "537/537 [==============================] - 0s - loss: 0.3846 - acc: 0.8045 - val_loss: 0.5093 - val_acc: 0.7835\n",
      "Epoch 133/150\n",
      "537/537 [==============================] - 0s - loss: 0.3918 - acc: 0.8156 - val_loss: 0.4910 - val_acc: 0.7792\n",
      "Epoch 134/150\n",
      "537/537 [==============================] - 0s - loss: 0.3805 - acc: 0.8343 - val_loss: 0.5263 - val_acc: 0.7792\n",
      "Epoch 135/150\n",
      "537/537 [==============================] - 0s - loss: 0.4053 - acc: 0.8175 - val_loss: 0.5211 - val_acc: 0.7706\n",
      "Epoch 136/150\n",
      "537/537 [==============================] - 0s - loss: 0.3917 - acc: 0.8138 - val_loss: 0.4979 - val_acc: 0.8009\n",
      "Epoch 137/150\n",
      "537/537 [==============================] - 0s - loss: 0.3866 - acc: 0.8305 - val_loss: 0.5051 - val_acc: 0.8009\n",
      "Epoch 138/150\n",
      "537/537 [==============================] - 0s - loss: 0.3849 - acc: 0.8194 - val_loss: 0.5129 - val_acc: 0.8009\n",
      "Epoch 139/150\n",
      "537/537 [==============================] - 0s - loss: 0.3963 - acc: 0.8082 - val_loss: 0.5128 - val_acc: 0.7879\n",
      "Epoch 140/150\n",
      "537/537 [==============================] - 0s - loss: 0.4180 - acc: 0.8082 - val_loss: 0.4945 - val_acc: 0.8009\n",
      "Epoch 141/150\n",
      "537/537 [==============================] - 0s - loss: 0.4037 - acc: 0.8119 - val_loss: 0.5315 - val_acc: 0.7749\n",
      "Epoch 142/150\n",
      "537/537 [==============================] - 0s - loss: 0.3961 - acc: 0.8287 - val_loss: 0.5189 - val_acc: 0.7662\n",
      "Epoch 143/150\n",
      "537/537 [==============================] - 0s - loss: 0.3897 - acc: 0.8194 - val_loss: 0.5112 - val_acc: 0.7835\n",
      "Epoch 144/150\n",
      "537/537 [==============================] - 0s - loss: 0.3864 - acc: 0.8231 - val_loss: 0.4912 - val_acc: 0.7749\n",
      "Epoch 145/150\n",
      "537/537 [==============================] - 0s - loss: 0.3927 - acc: 0.8194 - val_loss: 0.5455 - val_acc: 0.7835\n",
      "Epoch 146/150\n",
      "537/537 [==============================] - 0s - loss: 0.4027 - acc: 0.8138 - val_loss: 0.5328 - val_acc: 0.7749\n",
      "Epoch 147/150\n",
      "537/537 [==============================] - 0s - loss: 0.3833 - acc: 0.8063 - val_loss: 0.5241 - val_acc: 0.7706\n",
      "Epoch 148/150\n",
      "537/537 [==============================] - 0s - loss: 0.4022 - acc: 0.7933 - val_loss: 0.5076 - val_acc: 0.7879\n",
      "Epoch 149/150\n",
      "537/537 [==============================] - 0s - loss: 0.3826 - acc: 0.8231 - val_loss: 0.5069 - val_acc: 0.7706\n",
      "Epoch 150/150\n",
      "537/537 [==============================] - 0s - loss: 0.3911 - acc: 0.8250 - val_loss: 0.5158 - val_acc: 0.7965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb85c16bac8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# approach (1):  Fit and evaluate using a handy Keras function to do both\n",
    "model.fit(X, Y, nb_epoch=150, batch_size=10, validation_split= 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/154 [=====>........................] - ETA: 0sacc: 81.17%\n"
     ]
    }
   ],
   "source": [
    "# Approach (2):  manual evaluation\n",
    "# evaluate the model\n",
    "# Use only if not using the validation_split= 0.3 \n",
    "# i.e. if using -> model.fit(X_train, y_train, nb_epoch=150, batch_size=10)\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:bme6938]",
   "language": "python",
   "name": "conda-env-bme6938-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
